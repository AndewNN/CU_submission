{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 15:06:04.064366: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-16 15:06:04.071293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742112364.079576    8317 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742112364.082068    8317 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-16 15:06:04.090734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"airesearch/wangchanberta-base-att-spm-uncased\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text.strip()\n",
    "\n",
    "def read_dataset(qset):\n",
    "    train_df = pd.read_csv(f\"./dataset/processed/train_Q{qset}.csv\")\n",
    "    test_df = pd.read_csv(f\"./dataset/processed/test_Q{qset}.csv\")\n",
    "    val_df = pd.read_csv(f\"./dataset/processed/valid_Q{qset}.csv\")\n",
    "\n",
    "    train_texts = train_df['answer'].apply(clean_text)\n",
    "    train_labels = train_df['score'].astype(np.float32)\n",
    "    val_texts = val_df['answer'].apply(clean_text)\n",
    "    val_labels = val_df['score'].astype(np.float32)\n",
    "    test_texts = test_df['answer'].apply(clean_text)\n",
    "    test_ids = test_df['ID']\n",
    "\n",
    "    train_texts = pd.concat([train_texts, val_texts])\n",
    "    train_labels = pd.concat([train_labels, val_labels])\n",
    "\n",
    "    return train_texts, train_labels, val_texts, val_labels, test_texts, test_ids\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=505)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Question Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524334e4f6364c82a31e539ddd8abc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51602ca9404544f9a68c53a4d39656be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622b81cfb7004635980f6fc476615d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_set = 4\n",
    "\n",
    "train_texts, train_labels, val_texts, val_labels, test_texts, test_ids = read_dataset(question_set)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "val_dataset = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"ID\": test_ids})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25005\n",
      "[5, 6, 3, 1, 25004, 0, 2, 8]\n",
      "{'text': 'เพราะการนำ A/B testing มาใช้โดยให้ A test เป็นการวางตำแหน่งของโฆษณาไว้ที่เดิม และ B test เป็นการเปลี่ยนตำแหน่งของโฆษณา นั้นจะช่วยให้สามารถนำมาเปรียบเทียบกันได้ว่าการ test ทั้งสองแบบที่ผ่าน randomness มาแบบเดียวกันนั้น แบบใดสามารถเพิ่มจำนวนการคลิกโฆษณาของผู้ใช้ได้มากกว่ากัน', 'label': 1.0, 'input_ids': [5, 474, 4166, 10, 3, 101, 3, 10, 14152, 919, 10, 2530, 4537, 10, 3, 10, 14152, 11764, 727, 340, 16, 2153, 4603, 543, 222, 10, 3, 10, 14152, 10, 17, 1509, 340, 16, 2153, 10, 72, 7009, 6978, 26, 2437, 17559, 2275, 24, 10, 14152, 10, 859, 84, 9180, 10, 12118, 21191, 14141, 10, 26, 84, 276, 72, 10, 84, 609, 151, 286, 207, 24, 4475, 2153, 19038, 8124, 67, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(tokenizer.all_special_ids)\n",
    "print(train_dataset[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alll = []\n",
    "# for i in range(len(train_dataset)):\n",
    "#     for j in range(len(train_dataset[i]['input_ids'])):\n",
    "#         alll.append(train_dataset[i]['input_ids'][j])\n",
    "        # if train_dataset[i]['input_ids'][j] >= 25005:\n",
    "        #     print(i, j)\n",
    "            # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.unique(np.array(alll)))\n",
    "# print(len(np.unique(np.array(alll))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.unique(np.array(alll)):\n",
    "#     model(torch.tensor([[i]], device='cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 00:28, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.327013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.082587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.228686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.066508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.117042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.078869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.053803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.083976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.163678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.177348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.067544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.132545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.175568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.117533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.069269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.060505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=0.10666704972585042, metrics={'train_runtime': 28.7782, 'train_samples_per_second': 63.242, 'train_steps_per_second': 2.085, 'total_flos': 472310936970600.0, 'train_loss': 0.10666704972585042, 'epoch': 20.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20, # 10 -> 20 -> 20\n",
    "    run_name=\"run\",\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[363, 366, 373, 376, 377, 380, 383, 386, 393, 396, 397, 399, 404, 410, 411, 419, 423, 432, 439, 444, 445, 451]\n",
      "[[5.176763 ]\n",
      " [5.2175183]\n",
      " [5.1630387]\n",
      " [4.9565325]\n",
      " [4.7626443]\n",
      " [4.7150226]\n",
      " [5.062947 ]\n",
      " [5.116655 ]\n",
      " [4.758366 ]\n",
      " [5.076514 ]\n",
      " [1.5369546]\n",
      " [4.5852284]\n",
      " [5.003554 ]\n",
      " [3.8017702]\n",
      " [5.1215777]\n",
      " [4.058332 ]\n",
      " [1.3813007]\n",
      " [4.441548 ]\n",
      " [2.6489275]\n",
      " [4.7530046]\n",
      " [5.2296114]\n",
      " [5.108672 ]]\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset['ID'])\n",
    "print(predictions.predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f\"./output_tf/Q{question_set}.csv\"\n",
    "output = []\n",
    "coll = ['ID', 'Score']\n",
    "for i in range(len(test_dataset['ID'])):\n",
    "    # print(f\"{test_dataset['ID'][i]},{predictions.predictions[i][0]}\")\n",
    "    output.append([test_dataset['ID'][i], min(max(0, predictions.predictions[i][0]), 5)])\n",
    "\n",
    "df = pd.DataFrame(output, columns=coll)\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID     Score\n",
      "0   362  3.421832\n",
      "1   363  5.000000\n",
      "2   364  3.506828\n",
      "3   365  5.000000\n",
      "4   366  5.000000\n",
      "..  ...       ...\n",
      "85  447  1.933424\n",
      "86  448  0.764716\n",
      "87  449  1.222936\n",
      "88  450  1.270083\n",
      "89  451  5.000000\n",
      "\n",
      "[90 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "sets = [1, 2, 3, 4]\n",
    "all_out = []\n",
    "coll = ['ID', 'Score']\n",
    "for s in sets:\n",
    "    output_path = f\"./output_tf/Q{s}.csv\"\n",
    "    df = pd.read_csv(output_path)\n",
    "    sc, idd = df['Score'].tolist(), df['ID'].tolist()\n",
    "    for i in range(len(sc)):\n",
    "        all_out.append([idd[i], sc[i]])\n",
    "\n",
    "all_out = sorted(all_out, key=lambda x: x[0])\n",
    "\n",
    "df = pd.DataFrame(all_out, columns=coll)\n",
    "df.to_csv('./output_tf/all.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore\n",
    "\n",
    "in case of new prediction for any question set worser than the previous one, we can restore the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n",
      "372\n",
      "2.0915958881378174 2.0915958881378174\n",
      "\n",
      "374\n",
      "374\n",
      "1.0348477363586426 1.0348477363586426\n",
      "\n",
      "375\n",
      "375\n",
      "0.6046752333641052 0.6046752333641052\n",
      "\n",
      "381\n",
      "381\n",
      "1.5637779235839844 1.5637779235839844\n",
      "\n",
      "390\n",
      "390\n",
      "1.01014506816864 1.01014506816864\n",
      "\n",
      "395\n",
      "395\n",
      "2.3856542110443115 2.3856542110443115\n",
      "\n",
      "401\n",
      "401\n",
      "1.934255719184876 1.934255719184876\n",
      "\n",
      "402\n",
      "402\n",
      "4.538719654083252 4.538719654083252\n",
      "\n",
      "403\n",
      "403\n",
      "2.670741081237793 2.670741081237793\n",
      "\n",
      "405\n",
      "405\n",
      "0.8457199335098267 0.8457199335098267\n",
      "\n",
      "413\n",
      "413\n",
      "0.7458707094192505 0.7458707094192505\n",
      "\n",
      "421\n",
      "421\n",
      "1.0416152477264404 1.0416152477264404\n",
      "\n",
      "422\n",
      "422\n",
      "1.340225338935852 1.340225338935852\n",
      "\n",
      "424\n",
      "424\n",
      "1.058066487312317 1.058066487312317\n",
      "\n",
      "426\n",
      "426\n",
      "0.5104495286941528 0.5104495286941528\n",
      "\n",
      "430\n",
      "430\n",
      "5.0 5.0\n",
      "\n",
      "437\n",
      "437\n",
      "3.375184774398804 3.375184774398804\n",
      "\n",
      "442\n",
      "442\n",
      "3.966780662536621 3.966780662536621\n",
      "\n",
      "446\n",
      "446\n",
      "1.9142019748687744 1.9142019748687744\n",
      "\n",
      "448\n",
      "448\n",
      "0.7647156715393066 0.7647156715393066\n",
      "\n",
      "449\n",
      "449\n",
      "1.2229357957839966 1.2229357957839966\n",
      "\n",
      "450\n",
      "450\n",
      "1.2700825929641724 1.2700825929641724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restore_file = \"./output_tf/Q1.csv\"\n",
    "from_file = \"./output_tf/all_old.csv\"\n",
    "\n",
    "df = pd.read_csv(restore_file)\n",
    "df2 = pd.read_csv(from_file)\n",
    "\n",
    "#iterate over ID\n",
    "idx = 0\n",
    "for i in range(len(df)):\n",
    "    print(df['ID'][i])\n",
    "    while df['ID'][i] != df2['ID'][idx]:\n",
    "        idx += 1\n",
    "    print(df2['ID'][idx])\n",
    "    print(df['Score'][i], df2['Score'][idx])\n",
    "    print()\n",
    "    df.loc[i, 'Score'] = df2['Score'][idx]\n",
    "\n",
    "df.to_csv(restore_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
