{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API_KEY from .env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import json\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "config = {\n",
    "    \"API_KEY\": API_KEY,\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"store\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"./dataset/train.csv\")\n",
    "\n",
    "# Load OpenAI's token encoder for GPT-4 / GPT-3.5-turbo\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Function to estimate tokens for a given text\n",
    "def estimate_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Estimate tokens for each row in the dataset\n",
    "df[\"token_count\"] = df.apply(lambda row: estimate_tokens(row[\"question\"] + \" \" + row[\"answer\"]), axis=1)\n",
    "\n",
    "# Total estimated tokens\n",
    "total_tokens = df[\"token_count\"].sum()\n",
    "\n",
    "print(f\"Total estimated tokens: {total_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_jsonl(dataframe, filename, is_test=False):\n",
    "    jsonl_data = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        if not is_test:\n",
    "            example = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are an AI grader that evaluates student answers on a scale from 0 to 5 in steps of 0.25.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Question: {row['question']}\\nAnswer: {row['answer']}\"},\n",
    "                    {\"role\": \"assistant\", \"content\": f\"Score: {row['score']}\"}\n",
    "                ]\n",
    "            }\n",
    "        else:\n",
    "            example = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are an AI grader that evaluates student answers on a scale from 0 to 5 in steps of 0.25.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Question: {row['question']}\\nAnswer: {row['answer']}\"},\n",
    "                    {\"role\": \"assistant\", \"content\": \"Score:\"}\n",
    "                ],\n",
    "                \"id\": row[\"ID\"],\n",
    "            }\n",
    "        jsonl_data.append(example)\n",
    "\n",
    "    # Save to JSONL file\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for entry in jsonl_data:\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'set', 'question', 'answer', 'score'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14377/2764274778.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, train_data])\n",
      "/tmp/ipykernel_14377/2764274778.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  val_df = pd.concat([val_df, val_data])\n",
      "/tmp/ipykernel_14377/2764274778.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, train_data])\n",
      "/tmp/ipykernel_14377/2764274778.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  val_df = pd.concat([val_df, val_data])\n",
      "/tmp/ipykernel_14377/2764274778.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, train_data])\n",
      "/tmp/ipykernel_14377/2764274778.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  val_df = pd.concat([val_df, val_data])\n",
      "/tmp/ipykernel_14377/2764274778.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, train_data])\n",
      "/tmp/ipykernel_14377/2764274778.py:41: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  val_df = pd.concat([val_df, val_data])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"./dataset/test.csv\")\n",
    "grouped_data = df.groupby(\"set\")\n",
    "grouped_data_test = test_df.groupby(\"set\")\n",
    "cou = 0\n",
    "# for group, data in grouped_data:\n",
    "#     print(f\"Group: {group}\")\n",
    "#     unique_scores = data[\"score\"].unique()\n",
    "#     for score in unique_scores:\n",
    "#         data_all = data[data[\"score\"] == score]\n",
    "#         print(f\"Score: {score}\")\n",
    "#         print(f\"Total: {len(data_all)}\")\n",
    "#         cou += len(data_all)\n",
    "#     print()\n",
    "# print(f\"Total: {cou}\")\n",
    "col = df.columns\n",
    "print(col)\n",
    "\n",
    "num = {\"Q1\": 1, \"Q2\": 1, \"Q3\": 2, \"Q4\": 1}\n",
    "# print(col)\n",
    "\n",
    "path = \"./dataset/processed/\"\n",
    "for group, data in grouped_data:\n",
    "    # print(f\"Group: {group}\")\n",
    "    unique_scores = data[\"score\"].unique()\n",
    "\n",
    "    # empty df for each group question and append each score later\n",
    "    train_df, val_df = pd.DataFrame(columns=col), pd.DataFrame(columns=col)\n",
    "\n",
    "    for score in unique_scores:\n",
    "        data_all = data[data[\"score\"] == score]\n",
    "        # sample and drop for val set another is train set\n",
    "        # print(f\"Score: {score}\")\n",
    "        # print(f\"Total: {len(data_all)}\")\n",
    "        num_sam = num[group]\n",
    "        num_sam = max(0, min(num_sam, len(data_all)-1)) # reserved 1 for train\n",
    "        # print(f\"Sample: {num_sam}\")\n",
    "        val_data = data_all.sample(n=num_sam, random_state=42)\n",
    "        train_data = data_all.drop(val_data.index)\n",
    "        train_df = pd.concat([train_df, train_data])\n",
    "        val_df = pd.concat([val_df, val_data])\n",
    "\n",
    "    train_file = f\"{path}train_{group}.jsonl\"\n",
    "    valid_file = f\"{path}valid_{group}.jsonl\"\n",
    "\n",
    "    train_file_df = f\"{path}train_{group}.csv\"\n",
    "    valid_file_df = f\"{path}valid_{group}.csv\"\n",
    "    convert_to_jsonl(train_df, train_file)\n",
    "    convert_to_jsonl(val_df, valid_file)\n",
    "    # print(len(train_df), len(val_df))\n",
    "    pd.DataFrame(train_df).to_csv(train_file_df, index=False)\n",
    "    pd.DataFrame(val_df).to_csv(valid_file_df, index=False)\n",
    "\n",
    "for group, data in grouped_data_test:\n",
    "    test_file = f\"{path}test_{group}.jsonl\"\n",
    "    test_file_df = f\"{path}test_{group}.csv\"\n",
    "    convert_to_jsonl(data, test_file, is_test=True)\n",
    "\n",
    "    pd.DataFrame(data).to_csv(test_file_df, index=False)\n",
    "    # print(f\"Group: {group}\")\n",
    "    # print(f\"Total: {len(data)}\")\n",
    "    # print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./dataset/processed/train_Q1.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 435, 1408\n",
      "mean / median: 619.170731707317, 557.0\n",
      "p5 / p95: 474.7, 843.5000000000001\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Reading ./dataset/processed/train_Q2.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 398, 1050\n",
      "mean / median: 579.8915662650602, 567.0\n",
      "p5 / p95: 448.6, 727.4\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Reading ./dataset/processed/train_Q3.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 411, 894\n",
      "mean / median: 529.5487804878048, 513.0\n",
      "p5 / p95: 460.0, 629.0000000000001\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Reading ./dataset/processed/train_Q4.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 599, 1622\n",
      "mean / median: 952.7176470588236, 933.0\n",
      "p5 / p95: 718.0, 1185.0000000000002\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Reading ./dataset/processed/valid_Q1.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 452, 735\n",
      "mean / median: 622.6666666666666, 674.0\n",
      "p5 / p95: 477.6, 731.8\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Reading ./dataset/processed/valid_Q2.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 466, 589\n",
      "mean / median: 526.4285714285714, 530.0\n",
      "p5 / p95: 490.0, 562.6\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Reading ./dataset/processed/valid_Q3.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 457, 1085\n",
      "mean / median: 617.625, 530.0\n",
      "p5 / p95: 464.0, 916.3\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Reading ./dataset/processed/valid_Q4.jsonl\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 667, 1227\n",
      "mean / median: 930.0, 921.0\n",
      "p5 / p95: 671.5, 1197.5\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 6\n",
      "mean / median: 6.0, 6.0\n",
      "p5 / p95: 6.0, 6.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Total tokens: 243117\n"
     ]
    }
   ],
   "source": [
    "types = [\"train\", \"valid\"]\n",
    "# types = [\"test\"]\n",
    "qs = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "token_sum = 0\n",
    "\n",
    "for t in types:\n",
    "    for q in qs:\n",
    "        data_path = f\"{path}{t}_{q}.jsonl\"\n",
    "        print(f\"Reading {data_path}\")\n",
    "\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            dataset = [json.loads(line) for line in f]\n",
    "\n",
    "        format_errors = defaultdict(int)\n",
    "\n",
    "        for ex in dataset:\n",
    "            if not isinstance(ex, dict):\n",
    "                format_errors[\"data_type\"] += 1\n",
    "                continue\n",
    "                \n",
    "            messages = ex.get(\"messages\", None)\n",
    "            if not messages:\n",
    "                format_errors[\"missing_messages_list\"] += 1\n",
    "                continue\n",
    "                \n",
    "            for message in messages:\n",
    "                if \"role\" not in message or \"content\" not in message:\n",
    "                    format_errors[\"message_missing_key\"] += 1\n",
    "                \n",
    "                if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "                    format_errors[\"message_unrecognized_key\"] += 1\n",
    "                \n",
    "                if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                    format_errors[\"unrecognized_role\"] += 1\n",
    "                    \n",
    "                content = message.get(\"content\", None)\n",
    "                function_call = message.get(\"function_call\", None)\n",
    "                \n",
    "                if (not content and not function_call) or not isinstance(content, str):\n",
    "                    format_errors[\"missing_content\"] += 1\n",
    "            \n",
    "            if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "                format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "        if format_errors:\n",
    "            print(\"Found errors:\")\n",
    "            for k, v in format_errors.items():\n",
    "                print(f\"{k}: {v}\")\n",
    "        else:\n",
    "            print(\"No errors found\")\n",
    "        \n",
    "        n_missing_system = 0\n",
    "        n_missing_user = 0\n",
    "        n_messages = []\n",
    "        convo_lens = []\n",
    "        assistant_message_lens = []\n",
    "\n",
    "        for ex in dataset:\n",
    "            messages = ex[\"messages\"]\n",
    "            if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "                n_missing_system += 1\n",
    "            if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "                n_missing_user += 1\n",
    "            n_messages.append(len(messages))\n",
    "            convo_lens.append(num_tokens_from_messages(messages))\n",
    "            assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "            \n",
    "        print(\"Num examples missing system message:\", n_missing_system)\n",
    "        print(\"Num examples missing user message:\", n_missing_user)\n",
    "        print_distribution(n_messages, \"num_messages_per_example\")\n",
    "        print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "        print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "        n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "        print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")\n",
    "        token_sum += sum(convo_lens)\n",
    "print(f\"Total tokens: {token_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
