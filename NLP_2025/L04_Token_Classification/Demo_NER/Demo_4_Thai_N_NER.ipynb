{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtbN817bgMKl"
      },
      "source": [
        "# Thai N-NER: Thai Nested Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx3LanXugYwR"
      },
      "source": [
        "This demo notebook provides a tutorial on using Thai N-NER, with references from [Thai N-NER](https://medium.com/airesearch-in-th/thai-n-ner-thai-nested-named-entity-recognition-1969f8fe91f0)\n",
        "\n",
        "Learn more about Thai N-NER here : [Thai N-NER](https://medium.com/airesearch-in-th/thai-n-ner-thai-nested-named-entity-recognition-1969f8fe91f0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOy4tFSvbUUF"
      },
      "source": [
        "## 1. Setup and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OCej2IpilGT1",
        "outputId": "3b55ed1f-905a-41e5-92d9-f45600e50a84"
      },
      "outputs": [],
      "source": [
        "# !pip install seqeval\n",
        "# !pip install pythainlp\n",
        "# !pip install transformers==4.29.2\n",
        "# !pip install sentencepiece\n",
        "# !pip install gdown\n",
        "# !pip install thai_nner\n",
        "# !pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmmNNtCZuc84"
      },
      "source": [
        "# Model checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5THh4l5miJmJ"
      },
      "source": [
        "> Thai N-NER provides necessary resources, including models, datasets, and pre-trained language models, available here : [Thai N-NER (resources)](https://drive.google.com/drive/folders/1Dy-360iZ9hIA-xA0yizSwmpM8sx6rrjJ?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97UzrHEUuTEg"
      },
      "source": [
        "To utilize this, please follow these steps::\n",
        "\n",
        "1. Add the Shared Folder [Thai N-NER (resources)](https://drive.google.com/drive/folders/1Dy-360iZ9hIA-xA0yizSwmpM8sx6rrjJ?usp=sharing)  to Your Google Drive.\n",
        "* first open the shared folder link in your web browser\n",
        "* Click the folder named \"thai-nner\" at the top of the page.\n",
        "* In the menu bar, click \"Organize\", then click \"Add shortcut\" to Drive (you may see an icon that looks like a Drive logo with a plus sign)\n",
        "* Select \"My Drive\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt6m1CowIy4N",
        "outputId": "3d32f3bc-2577-4968-90c0-4ce89599941d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: './Thai-NNER'\n",
            "/home/andre/Desktop/CU_submission/NLP_2025/L04_Token_Classification/Demo_NER/Thai-NNER\n"
          ]
        }
      ],
      "source": [
        "# Clone github\n",
        "# !git clone https://github.com/vistec-AI/Thai-NNER.git\n",
        "%cd ./Thai-NNER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSwO2C8bbXy9"
      },
      "source": [
        "# Mount your drive to Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSWhdrPSQdLT",
        "outputId": "8c9f85a4-a2e2-4852-aaf6-dd1aab45251d"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "# # Create symbolic links\n",
        "# !ln -s \"./thai-nner/lm\" ./data/lm\n",
        "# !ln -s \"./thai-nner/checkpoints\" ./data/checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK0rqX03a5k4"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iIPgzaFwbFHI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "\n",
        "from utils.unique import unique\n",
        "import model.loss as module_loss\n",
        "import model.model as module_arch\n",
        "import model.metric as module_metric\n",
        "from parse_config import ConfigParser\n",
        "import data_loader.data_loaders as module_data\n",
        "\n",
        "PAD = '<pad>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7NCCAfGMa9rI"
      },
      "outputs": [],
      "source": [
        "resume = 'data/checkpoints/1102_151935/checkpoint.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9KF4xBfbGDz",
        "outputId": "22984f39-6b1b-47b8-ba1e-2fa222411588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint: data/checkpoints/1102_151935/checkpoint.pth ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_11305/2011583196.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(config.resume)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "args = argparse.ArgumentParser(description='PyTorch Template')\n",
        "args.add_argument('-c', '--config', default=None, type=str, help='config file path (default: None)')\n",
        "args.add_argument('-r', '--resume', default=f\"{resume}\", type=str, help='path to latest checkpoint (default: None)')\n",
        "args.add_argument('-d', '--device', default=None, type=str, help='indices of GPUs to enable (default: all)')\n",
        "args.add_argument('-f', '--file', default=None, type=str, help='Error')\n",
        "config = ConfigParser.from_args(args)\n",
        "logger = config.get_logger('test')\n",
        "\n",
        "# build model architecturea\n",
        "model = config.init_obj('arch', module_arch)\n",
        "\n",
        "# get function handles of loss and metrics\n",
        "criterion = getattr(module_loss, config['loss'])\n",
        "metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
        "\n",
        "logger.info('Loading checkpoint: {} ...'.format(config.resume))\n",
        "checkpoint = torch.load(config.resume)\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "if config['n_gpu'] > 1:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "print(config['n_gpu'])\n",
        "\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "layers_train = config._config['trainer']['layers_train']\n",
        "\n",
        "# prepare model for testing\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "total_loss = 0.0\n",
        "total_metrics = torch.zeros(len(metric_fns))\n",
        "# logger.info(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o_DMcY49-3nh"
      },
      "outputs": [],
      "source": [
        "# Loading only few testing examples.\n",
        "config.config['data_loader']['args']['sample_data'] = True\n",
        "\n",
        "data_loader = config.init_obj('data_loader', module_data)\n",
        "test_data_loader = data_loader.get_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohj_vlyCmnV1"
      },
      "source": [
        "> Now, Let's try using the pre-trained Thai N-NER model checkpoint to perform inference and predict NE tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quYDawPSbLAO",
        "outputId": "2775ff1c-c2aa-4c28-dc0c-fcb203822490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>|วันนี้|วันที่|27|มกราคม|25|68|เป็น|วันที่||อากาศ||ดีมาก|</s> \n",
            "\n",
            "[1, 2]         rel            วันนี้\n",
            "[2, 4]         day            วันที่27\n",
            "[2, 7]         date           วันที่27มกราคม2568\n",
            "[3, 4]         cardinal       27\n",
            "[4, 5]         month          มกราคม\n",
            "[5, 7]         year           2568\n"
          ]
        }
      ],
      "source": [
        "from utils.prediction import predict, get_dict_prediction, show\n",
        "\n",
        "\n",
        "\n",
        "text = \" วันนี้วันที่ 27 มกราคม 2568 เป็นวันที่อากาศดีมาก \"\n",
        "\n",
        "\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am_9zGIwpeTD",
        "outputId": "76e69cf5-1828-47e1-d245-873f1ca9eb48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>||คณะกรรมการ|40|ปี|14||ตุ|ลา|เพื่อ||ประชา||ธิ|ป||ไต|ร||สมบูรณ์|</s> \n",
            "\n",
            "[3, 4]         cardinal       40\n",
            "[3, 4]         cardinal       40\n",
            "[3, 5]         duration       40ปี\n",
            "[4, 5]         unit           ปี\n",
            "[5, 6]         day            14\n",
            "[6, 9]         month          ตุลา\n",
            "[10, 20]       norp_political ประชาธิปไตรสมบูรณ์\n"
          ]
        }
      ],
      "source": [
        "text = \"คณะกรรมการ 40 ปี 14 ตุลาเพื่อประชาธิปไตรสมบูรณ์\"\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ZNz615w_Qv",
        "outputId": "fa402d8d-6997-4296-b17f-f9ac33442a70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>|วันที่|18|มกราคม|25|68|เมื่อ|เวลา|11.|15|น|.|ที่|จ|.||นคร|พ|นม|นาย||ทักษิณ||ชิน|วั|ตร||อดีต|นาย|ก|ฯ|ให้||สัมภาษณ์||กรณี|นาย||ชา||ดา||ไทย||เศรษฐ|์||อดีต||รม|ช|.|ม|หาด|ไทย||เซ็น||คําสั่ง||เพ|ิก|ถอน||ที่ดิน||สนาม|กอล์ฟ||อัล|ไพ|น์||กลับ|คืน|เป็น|ที่|ธร|ณี|สงฆ์|ก่อน||หมด|วา|ระ||เพียง|ไม่||กี่|วัน|</s> \n",
            "\n",
            "[1, 3]         day            วันที่18\n",
            "[1, 6]         date           วันที่18มกราคม2568\n",
            "[2, 3]         cardinal       18\n",
            "[3, 4]         month          มกราคม\n",
            "[4, 6]         year           2568\n",
            "[7, 12]        time           เวลา11.15น.\n",
            "[8, 10]        cardinal       11.15\n",
            "[8, 12]        time           11.15น.\n",
            "[10, 12]       unit           น.\n",
            "[13, 19]       province       จ.นครพนม\n",
            "[15, 19]       province       นครพนม\n",
            "[19, 20]       title          นาย\n",
            "[19, 26]       person         นายทักษิณชินวัตร\n",
            "[20, 22]       firstname      ทักษิณ\n",
            "[22, 26]       last           ชินวัตร\n",
            "[26, 31]       role           อดีตนายกฯ\n",
            "[36, 37]       title          นาย\n",
            "[36, 46]       person         นายชาดาไทยเศรษฐ์\n",
            "[37, 41]       firstname      ชาดา\n",
            "[41, 46]       last           ไทยเศรษฐ์\n",
            "[46, 55]       role           อดีตรมช.มหาดไทย\n",
            "[52, 55]       goverment      มหาดไทย\n",
            "[65, 72]       facility_other สนามกอล์ฟอัลไพน์\n",
            "[68, 72]       facility_other อัลไพน์\n"
          ]
        }
      ],
      "source": [
        "text = \" วันที่ 18 มกราคม 2568 เมื่อเวลา 11.15 น. ที่จ.นครพนม นายทักษิณ ชินวัตร อดีตนายกฯ ให้สัมภาษณ์กรณีนายชาดา ไทยเศรษฐ์ อดีต รมช.มหาดไทย เซ็นคำสั่งเพิกถอนที่ดินสนามกอล์ฟอัลไพน์ กลับคืนเป็นที่ธรณีสงฆ์ ก่อนหมดวาระเพียงไม่กี่วัน \"\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoB0-oIFnd0E",
        "outputId": "ad4488c0-842e-4c96-9f79-df27133edb56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>|ส|ธ||.||กา|ง||ตัวเลข||เบื้องต้น|คน|ป่วย|จาก||ปัญหา||ฝุ่น|PM|2.5||แค่|3||สัปดาห์|ของ|เดือน|ม|.|ค|.||พุ่ง|14|4,000|คน||ส่วนใหญ่||ผิวหนัง||ตา||อักเสบ||โรค|ห|ืด||พบ|5|จังหวัด|ค่า||ฝุ่น||เกิน|75|ม|ค|ก|.|ต่อ||ลบ||.|ม|.||ต่อเนื่อง||เกิน|3|ใน||ระดับ||สีแดง|</s> \n",
            "\n",
            "[1, 5]         goverment      สธ.\n",
            "[23, 24]       cardinal       3\n",
            "[23, 26]       duration       3สัปดาห์\n",
            "[24, 26]       unit           สัปดาห์\n",
            "[27, 32]       month          เดือนม.ค.\n",
            "[28, 32]       month          ม.ค.\n",
            "[34, 36]       cardinal       144,000\n",
            "[34, 37]       quantity       144,000คน\n",
            "[36, 37]       unit           คน\n",
            "[41, 45]       disease        ตาอักเสบ\n",
            "[51, 52]       cardinal       5\n",
            "[52, 53]       unit           จังหวัด\n",
            "[58, 59]       cardinal       75\n",
            "[59, 63]       unit           มคก.\n",
            "[64, 70]       unit           ลบ.ม.\n",
            "[74, 75]       cardinal       3\n"
          ]
        }
      ],
      "source": [
        "text = \" สธ.กางตัวเลขเบื้องต้นคนป่วยจากปัญหาฝุ่น PM2.5 แค่ 3 สัปดาห์ของเดือน ม.ค.พุ่ง 144,000 คนส่วนใหญ่ผิวหนัง ตาอักเสบ โรคหืด พบ 5 จังหวัดค่าฝุ่นเกิน 75 มคก.ต่อ ลบ.ม.ต่อเนื่องเกิน 3 ในระดับสีแดง \"\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
